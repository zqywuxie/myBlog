---
title: Nginx
date: 2023-02-23 15:20:37
permalink: /pages/28823c/
---
[部分图源,笔记来自](https://www.cnblogs.com/LiuQizhong/p/11757420.html)

[视频](https://www.bilibili.com/video/av68136734/)

# Nginx

## 简介

### 介绍

Nginx (engine x) 是一个高性能的HTTP和反向代理**web服务器**  ，同时也提供了IMAP/POP3/SMTP服务。其特点是**占有内存少，并发能力强**，能经受高负载的考研，事实上nginx的并发能力在同类型的网页服务器中表现较好。

### 代理

1. 正向代理（梯子）

当客户端主动使用代理服务器时，此时的代理叫正向代理。

![代理](https://img-blog.csdnimg.cn/f2b98d4239e343dd9b27ab70fef82ef2.png#pic_center)

2. 反向代理

客户端对代理无感知，不需要任何配置进行访问，将请求发送到反向代理服务器，反向代理服务器去选择目标服务器获得数据后，返回给客户端。此时对于服务器而言代理只知道代理服务器IP，隐藏了真实服务器IP。

![反向代理](https://img-blog.csdnimg.cn/1014ebc0f2954dec8f230ee3082133d0.jpeg#pic_center)



#### 区别

1.用途不同。正向代理的典型用途是为在防火墙内的局域网客户端提供访问Internet的途径。正向代理还可以使用缓冲特性减少网络使用率。反向代理的典型用途是将防火墙后面的服务器提供给Internet用户访问。

2.安全性不同。正向代理允许客户端通过它访问任意网站并且隐藏客户端自身，因此你必须采取安全措施以确保仅为经过授权的客户端提供服务。反向代理对外都是透明的，访问者并不知道自己访问的是一个代理。

3.目的不同。正向代理实际代理的是客户端。反向代理代理的是目标服务器。

4.代理不同。正向代理是客户端架构，而反向代理是服务器架构。

5.服务对象不同。正向代理中，服务器不知道真正的用户是谁。反向代理中，用户不知道真正的服务器是谁。

6.功能不同。正向代理主要用来解决访问问题。反向代理主要用于解决负载均衡、安全防护，但二者都能提高访问速度。

### 负载均衡

> 尽力将网络流量平均分发到多个服务器上，以提高系统整体的响应速度和可用性。

单个服务器在并发量高的情况下，容易造成崩溃。（集群）就增加服务器数量，将请求分发到各个服务器上。

### 动静分离

为加快网站解析，动态页面和静态页面交给不同服务器进行处理。严格意义上说应该是动态请求跟静态请求分开，可以理解成使用 Nginx处理静态页面，Tomcat 处理动态页面。

![img](
https://wuxie-image.oss-cn-chengdu.aliyuncs.com/2023/04/02/20230223152157.png)



## 安装

linux环境进行安装

https://www.runoob.com/linux/nginx-install-setup.html



```sh
/usr/local/webserver/nginx/sbin/nginx -v  查看版本

/usr/local/webserver/nginx/conf/nginx.conf 配置文件

/usr/local/webserver/nginx/sbin ./nginx -s reload            # 重新载入配置文件
/usr/local/webserver/nginx/sbin ./nginx -s reopen            # 重启 Nginx
/usr/local/webserver/nginx/sbin ./nginx -s 
stop              # 停止 Nginx
```



### 配置介绍

#### 1.全局块

```tex

#user  nobody;
worker_processes  1; # 指明了nginx要开启的进程数

.....

#pid        logs/nginx.pid;

```



#### 2.events块

```tex
events {
    worker_connections  1024; # 单个工作进程（worker）可以允许同时建立外部连接的数量
}
```



#### 3.http块

1）全局块

文件引入，日志自定义,连接超时时间等

2）server块

```tex
server {
        listen       80; # 端口号
        server_name  localhost; # 主机名字

        #charset koi8-r;

        #access_log  logs/host.access.log  main;

		# 根据路径进行一个操作
        location / {
            root   html;
            index  index.html index.htm;
        }

```



## 代理实例

### 反向代理1

1.实现效果

1）打开浏览器，在浏览器地址输入`www.123.com`地址，然后跳转到tomcat主界面d

2.准备工作

1）在linux系统安装tomcat，使用默认端口

3.实现分析

​	在本机的hosts文件里面的进行修改映射，访问`www.123.com` 转移到nginx，通过其代理访问到`localhost:8080`

4.实现

1）修改hosts

windows下

```sh
c/Windos/System32/drivers/etc/HOST
```

ubuntu下

```sh
/etc/hosts

ip地址  www.123.com
```

 查看ip

```sh
ip addr show

ifconfig
```

![](
https://wuxie-image.oss-cn-chengdu.aliyuncs.com/2023/04/02/image-20230222192732263.png)



2）修改nginx配置

记得linux下防火墙开放端口

```sh
server {
        listen       80;
        server_name  IP地址; # 换成自己的IP

        #charset koi8-r;

        #access_log  logs/host.access.log  main;

        location / {
            root   html;
            # 添加代理IP
            proxy_pass http://127.0.0.1:8080
            index  index.html index.htm;
        }
```





### 反向代理2

1.实现效果

使用nginx反向代理，根据访问路径跳转不同端口的服务中

```sh
nginx使用9001端口
访问
localhost:9001/edu/,跳转localhost:8080
localhost:9001/vod/,跳转localhost:8081
```



2.实现

准备两个tomcat服务器

3.修改nginx.conf

```sh
server {
    listen       9001;
    server_name  访问者IP地址;

    location ~ /edu {
            root   html;
            proxy_pass http://127.0.0.1:8080;
    }
    
    location ~ /vod {
    		root html;
    		proxy_pass http://127.0.0.1:8080;
    }
}

```

```sh
客户端访问
localhost;9001/vod/a.html

就对应到了服务端:8080/vod/a.html
```



NginxLocation正则表达式

```sh
1.= 表示完全匹配才执行
2.~ 表示执行正则表达式,但区分大小
location ~ /documents/Abc {  # 匹配任何以 /documents/Abc 开头的地址，匹配符合以后，还要继续往下搜索

3.~* 同上,不区分大小写
location ~* \.(gif|jpg|jpeg)$ {  # 匹配所有以 gif,jpg或jpeg 结尾的请求

4.^~ 
location ^~ /images/ {  # 匹配任何以 /images/ 开头的地址，匹配符合以后，停止往下搜索正则，采用这一条。
```



在nginx中配置proxy_pass代理转发时，如果在proxy_pass后面的url加/，表示绝对根路径；如果没有/，表示相对路径，把匹配的路径部分也给代理走。

```sh
假设下面四种情况分别用 http://192.168.1.1/proxy/test.html 进行访问。

第一种：location /proxy/ {
    proxy_pass http://127.0.0.1/;
}
代理到URL：http://127.0.0.1/test.html

第二种（相对于第一种，最后少一个 / ）
location /proxy/ {
    proxy_pass http://127.0.0.1;
}
代理到URL：http://127.0.0.1/proxy/test.html

第三种：location /proxy/ {
    proxy_pass http://127.0.0.1/aaa/;
}
代理到URL：http://127.0.0.1/aaa/test.html

第四种（相对于第三种，最后少一个 / ）
location /proxy/ {
    proxy_pass http://127.0.0.1/aaa;
}
代理到URL：http://127.0.0.1/aaatest.html
```



### 反向代理3(负载均衡)

1、实现效果
（1）浏览器地址栏输入地址 http://192.168.17.129/edu/a.html，负载均衡效果，平均 8080和 8081 端口中

2、准备工作
（1）准备两台 tomcat 服务器，一台 8080，一台 8081

（2）在两台 tomcat 里面 webapps 目录中，创建名称是 edu 文件夹，在 edu 文件夹中创建页面 a.html，用于测试

3.修改nginx 配置

```sh

# 添加负载均衡的配置
upstream myserver{
# weight 表示负载均衡的比重
	server 192.168.29.134:8080 weight=4;
	server 192.168.29.134:8081 weight=2;
}

server {
        listen       80;
        server_name  192.168.29.134;
        
        location / {
            root   html;
            index  index.html index.htm;
            proxy_pass http://myserver # 列出复杂均衡的列表
        }
```



4.分配服务器策略

**第一种 轮询（默认）**

每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器 down 掉，能自动剔除。

**第二种 weight**

weight 代表权重默认为 1,权重越高被分配的客户端越多

  ![img](
https://wuxie-image.oss-cn-chengdu.aliyuncs.com/2023/04/02/20230223152650.png)

**第三种 ip_hash**

每个请求按访问 ip 的 hash 结果分配，这样每个访客固定访问一个后端服务器。解决session问题

 ![img](
https://wuxie-image.oss-cn-chengdu.aliyuncs.com/2023/04/02/20230223152708.png)

**第四种 fair（第三方）**

按后端服务器**的响应时间来分配请求**，响应时间短的优先分配。

 ![img](
https://wuxie-image.oss-cn-chengdu.aliyuncs.com/2023/04/02/20230223152721.png)





### 反向代理4(动静分离)

动静分离从目前实现角度来讲大致分为两种，

一种是纯粹把静态文件独立成单独的域名，放在独立的服务器上，也是目前主流推崇的方案；

另外一种方法就是动态跟静态文件混合在一起发布，通过 nginx 来分开。



> 通过 location 指定不同的后缀名实现不同的请求转发。通过 expires 参数设置，可以使浏览器缓存过期时间，减少与服务器之前的请求和流量。
>
> 具体 Expires 定义：是给一个资源设定一个过期时间，也就是说无需去服务端验证，直接通过浏览器自身确认是否过期即可
>
> 所以不会产生额外的流量。此种方法非常适合不经常变动的资源。（**如果经常更新的文件，不建议使用 Expires 来缓存**）
>
> 我这里设置 3d，表示在这 3 天之内访问这个 URL，发送一个请求，比对服务器该文件最后更新时间没有变化，则不会从服务器抓取，返回状态码 304
>
> 如果有修改，则直接从服务器重新下载，返回状态码 200。



**2、准备工作**

在 liunx 系统中准备静态资源，用于进行访问

  ![img](
https://wuxie-image.oss-cn-chengdu.aliyuncs.com/2023/04/02/20230223152805.png)

**3、具体配置**

在 nginx 配置文件中进行配置

![img](
https://wuxie-image.oss-cn-chengdu.aliyuncs.com/2023/04/02/20230223152815.png)



```sh
location /www/{
	root /data/;
	index index.html index.htm;
}

location /image/{
	root /data/;
	autoindex on; # 打开目录浏览功能
}
```

[autoindex设置](https://www.zhihu.com/question/531586933?ssr_src=heifetz&utm_id=0)

**4、最终测试**

（1）浏览器中输入地址

http://192.168.17.129/image/01.jpg

 ![img](
https://wuxie-image.oss-cn-chengdu.aliyuncs.com/2023/04/02/20230223152835.png)

因为配置文件 autoindex on

 ![img](
https://wuxie-image.oss-cn-chengdu.aliyuncs.com/2023/04/02/20230223152844.png)

（2）输入

http://192.168.17.129/www/a.html

![image-20230222210038078](
https://wuxie-image.oss-cn-chengdu.aliyuncs.com/2023/04/02/image-20230222210038078.png)



重点是添加 location，

最后检查 Nginx 配置是否正确即可，然后测试动静分离是否成功，之需要删除后端 tomcat

服务器上的某个静态文件，查看是否能访问，如果可以访问说明静态资源 nginx 直接返回了，不走后端 tomcat 服务器





### 高可用

#### 介绍

nginx宕机，请求无法实现效果；

实现：设置nginx集群，当主master宕机后，请求就转移到备份的nginx服务器；（使用keepalived软件实现）

#### keepalived

> **Keepalived** 提供了很好的`高可用性保障服务`，它可以检查服务器的状态，如果有服务器出现问题，**Keepalived 会将其从系统中移除，并且同时使用备份服务器代替该服务器的工作**，当这台服务器可以正常工作后，Keepalived 再将其放入服务器群中，这个过程是 Keepalived 自动完成的，不需要人工干涉，我们只需要修复出现问题的服务器即可。



![img](https://pic1.zhimg.com/80/v2-2784a5063dfcd3043c3a45b27c1e9ac4_720w.webp)



##### 配置文件

`/etc/keepalived/keepalived.conf`
:::details

```sh

# 全局配置
global_defs {
   # 邮件通知信息
   notification_email {
     # 定义收件人
     acassen@firewall.loc
   }
   # 定义发件人
   notification_email_from Alexandre.Cassen@firewall.loc
   # SMTP服务器地址
   smtp_server 192.168.200.1
   smtp_connect_timeout 30
   # 路由器标识，一般不用改，也可以写成每个主机自己的主机名
   router_id LVS_DEVEL
   
   # VRRP的ipv4和ipv6的广播地址，配置了VIP的网卡向这个地址广播来宣告自己的配置信息，下面是默认值
   vrrp_mcast_group4 224.0.0.18
   vrrp_mcast_group6 ff02::12
}

# 定义用于实例执行的脚本内容，比如可以在线降低优先级，用于强制切换
vrrp_script SCRIPT_NAME {
	script  /usr/local/xxx #脚本路径
	interval 2 # 检测脚本执行间隔，每隔2s执行
	weight #优先级
}

# 一个vrrp_instance就是定义一个虚拟路由器的，实例名称
vrrp_instance VI_1 {
    # 定义初始状态，可以是MASTER或者BACKUP
    state MASTER
    
    # 工作接口，通告选举使用哪个接口进行，ifconfig可以查看
    interface ens33
    
    # 虚拟路由ID，如果是一组虚拟路由就定义一个ID，如果是多组就要定义多个，而且这个虚拟
    #ID还是虚拟MAC最后一段地址的信息，取值范围0-255
    virtual_router_id 51
    # 使用哪个虚拟MAC地址
    use_vmac XX:XX:XX:XX:XX
    # 监控本机上的哪个网卡，网卡一旦故障则需要把VIP转移出去 
    track_interface {
        eth0
        ens33
    }
    # 如果你上面定义了MASTER,这里的优先级就需要定义的比其他的高
    priority 100
    # 通告频率，单位为秒
    advert_int 1
    # 通信认证机制，这里是明文认证还有一种是加密认证
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    # 设置虚拟VIP地址，一般就设置一个，在LVS中这个就是为LVS主机设置VIP的，这样你就不用自己手动设置了
    virtual_ipaddress {
        # IP/掩码 dev 配置在哪个网卡
        192.168.200.16/24 dev eth1
        # IP/掩码 dev 配置在哪个网卡的哪个别名上
        192.168.200.17/24 dev label eth1:1
    }
    # 虚拟路由，在需要的情况下可以设置lvs主机 数据包在哪个网卡进来从哪个网卡出去
    virtual_routes {
        192.168.110.0/24 dev eth2
    }
    # 工作模式，nopreempt表示工作在非抢占模式，默认是抢占模式 preempt
    nopreempt|preempt
    # 如果是抢占默认则可以设置等多久再抢占，默认5分钟
    preempt delay 300
    # 追踪脚本，通常用于去执行上面的vrrp_script定义的脚本内容
    track_script {

    }
    # 三个指令，如果主机状态变成Master|Backup|Fault之后会去执行的通知脚本，脚本要自己写
    notify_master ""
    notify_backup ""
    notify_fault ""
}

# 定义LVS集群服务，可以是IP+PORT；也可以是fwmark 数字，也就是防火墙规则
# 所以通过这里就可以看出来keepalive天生就是为ipvs而设计的
virtual_server 10.10.10.2 1358 {
    delay_loop 6
    # 算法
    lb_algo rr|wrr|lc|wlc|lblc|sh|dh 
    # LVS的模式
    lb_kind NAT|DR|TUN
    # 子网掩码，这个掩码是VIP的掩码
    nat_mask 255.255.255.0
    # 持久连接超时时间
    persistence_timeout 50
    # 定义协议
    protocol TCP
    # 如果后端应用服务器都不可用，就会定向到那个服务器上
    sorry_server 192.168.200.200 1358

    # 后端应用服务器 IP PORT
    real_server 192.168.200.2 1358 {
        # 权重
        weight 1
        # MSIC_CHECK|SMTP_CHEKC|TCP_CHECK|SSL_GET|HTTP_GET这些都是
        # 针对应用服务器做健康检查的方法
        MISC_CHECK {}
        # 用于检查SMTP服务器的
        SMTP_CHEKC {}

        # 如果应用服务器不是WEB服务器，就用TCP_CHECK检查
        TCP_CHECK {
          # 向哪一个端口检查，如果不指定默认使用上面定义的端口
          connect_port <PORT>
          # 向哪一个IP检测，如果不指定默认使用上面定义的IP地址
          bindto <IP>
          # 连接超时时间
          connect_timeout 3
        }

        # 如果对方是HTTPS服务器就用SSL_GET方法去检查，里面配置的内容和HTTP_GET一样
        SSL_GET {}

        # 应用服务器UP或者DOWN，就执行那个脚本
        notify_up "这里写的是路径，如果脚本后有参数，整体路径+参数引起来"
        notify_down "/PATH/SCRIPTS.sh 参数"

        # 使用HTTP_GET方法去检查
        HTTP_GET {
            # 检测URL
            url { 
              # 具体检测哪一个URL
              path /testurl/test.jsp
              # 检测内容的哈希值
              digest 640205b7b0fc66c1ea91c463fac6334d
              # 除了检测哈希值还可以检测状态码，比如HTTP的200 表示正常，两种方法二选一即可
              status_code 200
            }
            url { 
              path /testurl2/test.jsp
              digest 640205b7b0fc66c1ea91c463fac6334d
            }
            url { 
              path /testurl3/test.jsp
              digest 640205b7b0fc66c1ea91c463fac6334d
            }
            # 向哪一个端口检查，如果不指定默认使用上面定义的端口
            connect_port <PORT>
            # 向哪一个IP检测，如果不指定默认使用上面定义的IP地址
            bindto <IP>
            # 连接超时时间
            connect_timeout 3
            # 尝试次数
            nb_get_retry 3
            # 每次尝试之间间隔几秒
            delay_before_retry 3
        }
    }

    real_server 192.168.200.3 1358 {
        weight 1
        HTTP_GET {
            url { 
              path /testurl/test.jsp
              digest 640205b7b0fc66c1ea91c463fac6334c
            }
            url { 
              path /testurl2/test.jsp
              digest 640205b7b0fc66c1ea91c463fac6334c
            }
            connect_timeout 3
            nb_get_retry 3
            delay_before_retry 3
        }
    }
}

```
:::


启动

```sh
# 启动keepalived
systemctl start keepalived
# 停止keepalived
systemctl stop keepalived
# 重启keepalived
systemctl restart keepalived
```

#### 最终测试

虚拟IP都绑定在主从服务器上

1）输入虚拟IP进行访问主服务器；

![image-20230223144243251](
https://wuxie-image.oss-cn-chengdu.aliyuncs.com/2023/04/02/image-20230223144243251.png)



2）停止主服务器，再次输入虚拟IP，还可以继续访问



## 原理

### 1、master和worker

![img](
https://wuxie-image.oss-cn-chengdu.aliyuncs.com/2023/04/02/20230223152933.png)



![image-20230223145247171](
https://wuxie-image.oss-cn-chengdu.aliyuncs.com/2023/04/02/image-20230223145247171.png)



### 2、worker工作

![img](
https://wuxie-image.oss-cn-chengdu.aliyuncs.com/2023/04/02/20230223152945.png)

worker通过争抢机制获得任务



### 3、一个master和多个worker好处

1）可以使用nginx-s reload 进行热部署

> - 1）改变了nginx配置之后，HUP signal的信号需要发送给主进程。
> - 2）主进程首先会检测新配置的语法有效性。
> - 3）尝试应用新的配置
>   - 1.打开日志文件，并且新分配一个socket来监听。
>   - 2.如果1失败，则回滚改变，还是会使用原有的配置。
>   - 3.如果1成功，则使用新的配置，新建一个线程。新建成功后发送一个关闭消息给旧的进程。要求旧线程优雅的关闭。
> - 4.旧的线程 受到信号后会继续服务，当所有请求的客户端被服务后，旧线程关闭。



2）独立进程，一个进程退出后，其他进程还在继续工作，服务不会中断



### 4、worker数设置

nginx同redis采用**io多路复用机制**（linux下，windows没有），每个worker独立线程，通过**异步非阻塞**方式处理请求。

**worker 数和服务器的 cpu 数相等是最为适宜的**



### 5、连接数worker_connection

![img](
https://wuxie-image.oss-cn-chengdu.aliyuncs.com/2023/04/02/20230223153003.png)

1、发送请求，占用worker几个连接数

> 访问静态资源占用**两个**连接数，**客户端请求，nginx返回**
>
> 访问动态资源如需要tomcat查询数据库等，需要四个

2、nginx 有一个 master，有四个 woker，每个 woker 支持最大的连接数 1024，支持的最大并发数是多少？

**最大并发数：能请求多大请求**

> 普通的静态访问最大并发数是： worker_connections * worker_processes /2，4*1024/2
>
> 如果是 HTTP 作 为反向代理来说，最大并发数量应该是 worker_connections *
>
> 如果是 HTTP 作 为反向代理来说，最大并发数量应该是 worker_connections *
>
> worker_processes/4。